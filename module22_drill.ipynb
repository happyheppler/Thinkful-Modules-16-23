{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRILL: Improve this gradient boost model\n",
    "\n",
    "We'll still use the European Social Survey Data, but now with a categorical outcome: Whether or not someone lives with a partner.\n",
    "\n",
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement.  Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set.  Strategies you might use include:\n",
    "\n",
    "* Creating new features\n",
    "* Applying more overfitting-prevention strategies like subsampling\n",
    "* More iterations\n",
    "* Trying a different loss function\n",
    "* Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntry</th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CH</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CH</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CH</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CH</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8589</td>\n",
       "      <td>SE</td>\n",
       "      <td>3729.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8590</td>\n",
       "      <td>SE</td>\n",
       "      <td>3732.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8591</td>\n",
       "      <td>SE</td>\n",
       "      <td>3743.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8592</td>\n",
       "      <td>SE</td>\n",
       "      <td>3744.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8593</td>\n",
       "      <td>SE</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8147 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cntry    idno  year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  \\\n",
       "0       CH     5.0     6    3.0      3.0     10.0     5.0    8.0      5.0   \n",
       "1       CH    25.0     6    6.0      5.0      7.0     5.0    9.0      3.0   \n",
       "2       CH    26.0     6    1.0      8.0      8.0     8.0    7.0      6.0   \n",
       "3       CH    28.0     6    4.0      6.0      6.0     7.0   10.0      6.0   \n",
       "4       CH    29.0     6    5.0      6.0      7.0     5.0    8.0      7.0   \n",
       "...    ...     ...   ...    ...      ...      ...     ...    ...      ...   \n",
       "8589    SE  3729.0     7    3.0      4.0      5.0     3.0    6.0      6.0   \n",
       "8590    SE  3732.0     7    5.0      6.0      4.0     4.0   10.0      6.0   \n",
       "8591    SE  3743.0     7    4.0      5.0      7.0     6.0    8.0      6.0   \n",
       "8592    SE  3744.0     7    5.0      8.0      8.0     6.0    9.0      7.0   \n",
       "8593    SE  3746.0     7    2.0      6.0      7.0     5.0    7.0      7.0   \n",
       "\n",
       "      sclact  gndr  agea  partner  \n",
       "0        4.0   2.0  60.0      1.0  \n",
       "1        2.0   2.0  59.0      1.0  \n",
       "2        3.0   1.0  24.0      2.0  \n",
       "3        2.0   2.0  64.0      1.0  \n",
       "4        2.0   2.0  55.0      1.0  \n",
       "...      ...   ...   ...      ...  \n",
       "8589     2.0   1.0  18.0      2.0  \n",
       "8590     3.0   1.0  15.0      2.0  \n",
       "8591     3.0   1.0  44.0      2.0  \n",
       "8592     3.0   1.0  15.0      2.0  \n",
       "8593     4.0   2.0  15.0      2.0  \n",
       "\n",
       "[8147 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define outcome and predictors\n",
    "# Set our outcome to 0 and 1\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll make 500 iterations, using 2-deep trees, and set our loss function\n",
    "params = {'n_estimators': 500,\n",
    "         'max_depth': 2,\n",
    "         'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0, 1.0] / table_train.loc['All', 'All']\n",
    "train_tII_errors = table_train.loc[1.0, 0.0] / table_train.loc['All', 'All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0, 1.0] / table_test.loc['All', 'All']\n",
    "test_tII_errors = table_test.loc[1.0, 0.0] / table_test.loc['All', 'All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GridSearchCV to optimize model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'loss': ['deviance', 'exponential'],\n",
    "          'n_estimators': [500, 1000, 1500],\n",
    "          'max_depth': np.arange(2, 8, 2),\n",
    "          'learning_rate': [0.01, 0.5, 0.1, 0.2],\n",
    "          'subsample': [0.5, 1.0]\n",
    "}\n",
    "\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "clf = GridSearchCV(gbc, params, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.029484029484029485\n",
      "Percent Type II errors: 0.18673218673218672\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06082094640665485\n",
      "Percent Type II errors: 0.195963452884222\n"
     ]
    }
   ],
   "source": [
    "# Set parameters to optimized values\n",
    "params = {'loss': 'deviance',\n",
    "          'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'learning_rate': 0.01,\n",
    "          'subsample': 0.5\n",
    "}\n",
    "\n",
    "# Initialize and fit the model\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0, 1.0] / table_train.loc['All', 'All']\n",
    "train_tII_errors = table_train.loc[1.0, 0.0] / table_train.loc['All', 'All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0, 1.0] / table_test.loc['All', 'All']\n",
    "test_tII_errors = table_test.loc[1.0, 0.0] / table_test.loc['All', 'All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'loss': ['deviance'],\n",
    "          'n_estimators': [500, 1000, 1500],\n",
    "          'max_depth': np.arange(2, 8, 2),\n",
    "}\n",
    "\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "clf = GridSearchCV(gbc, params, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.10609573162416473\n",
      "Percent Type II errors: 0.18437201690985955\n"
     ]
    }
   ],
   "source": [
    "# Set parameters to optimized values\n",
    "params = {'loss': 'deviance',\n",
    "          'n_estimators': 1000,\n",
    "          'max_depth': 6\n",
    "}\n",
    "\n",
    "# Initialize and fit the model\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0, 1.0] / table_train.loc['All', 'All']\n",
    "train_tII_errors = table_train.loc[1.0, 0.0] / table_train.loc['All', 'All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0, 1.0] / table_test.loc['All', 'All']\n",
    "test_tII_errors = table_test.loc[1.0, 0.0] / table_test.loc['All', 'All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
