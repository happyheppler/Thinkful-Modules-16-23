{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRILL: Improve this gradient boost model\n",
    "\n",
    "We'll still use the European Social Survey Data, but now with a categorical outcome: Whether or not someone lives with a partner.\n",
    "\n",
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement.  Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set.  Strategies you might use include:\n",
    "\n",
    "* Creating new features\n",
    "* Applying more overfitting-prevention strategies like subsampling\n",
    "* More iterations\n",
    "* Trying a different loss function\n",
    "* Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntry</th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CH</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CH</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CH</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CH</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8589</td>\n",
       "      <td>SE</td>\n",
       "      <td>3729.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8590</td>\n",
       "      <td>SE</td>\n",
       "      <td>3732.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8591</td>\n",
       "      <td>SE</td>\n",
       "      <td>3743.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8592</td>\n",
       "      <td>SE</td>\n",
       "      <td>3744.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8593</td>\n",
       "      <td>SE</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8147 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cntry    idno  year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  \\\n",
       "0       CH     5.0     6    3.0      3.0     10.0     5.0    8.0      5.0   \n",
       "1       CH    25.0     6    6.0      5.0      7.0     5.0    9.0      3.0   \n",
       "2       CH    26.0     6    1.0      8.0      8.0     8.0    7.0      6.0   \n",
       "3       CH    28.0     6    4.0      6.0      6.0     7.0   10.0      6.0   \n",
       "4       CH    29.0     6    5.0      6.0      7.0     5.0    8.0      7.0   \n",
       "...    ...     ...   ...    ...      ...      ...     ...    ...      ...   \n",
       "8589    SE  3729.0     7    3.0      4.0      5.0     3.0    6.0      6.0   \n",
       "8590    SE  3732.0     7    5.0      6.0      4.0     4.0   10.0      6.0   \n",
       "8591    SE  3743.0     7    4.0      5.0      7.0     6.0    8.0      6.0   \n",
       "8592    SE  3744.0     7    5.0      8.0      8.0     6.0    9.0      7.0   \n",
       "8593    SE  3746.0     7    2.0      6.0      7.0     5.0    7.0      7.0   \n",
       "\n",
       "      sclact  gndr  agea  partner  \n",
       "0        4.0   2.0  60.0      1.0  \n",
       "1        2.0   2.0  59.0      1.0  \n",
       "2        3.0   1.0  24.0      2.0  \n",
       "3        2.0   2.0  64.0      1.0  \n",
       "4        2.0   2.0  55.0      1.0  \n",
       "...      ...   ...   ...      ...  \n",
       "8589     2.0   1.0  18.0      2.0  \n",
       "8590     3.0   1.0  15.0      2.0  \n",
       "8591     3.0   1.0  44.0      2.0  \n",
       "8592     3.0   1.0  15.0      2.0  \n",
       "8593     4.0   2.0  15.0      2.0  \n",
       "\n",
       "[8147 rows x 13 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define outcome and predictors\n",
    "# Set our outcome to 0 and 1\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04495933711830597\n",
      "Percent Type II errors: 0.17922356912689888\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06134969325153374\n",
      "Percent Type II errors: 0.18159509202453988\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, using 2-deep trees, and set our loss function\n",
    "params = {'n_estimators': 500,\n",
    "         'max_depth': 2,\n",
    "         'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0, 1.0] / table_train.loc['All', 'All']\n",
    "train_tII_errors = table_train.loc[1.0, 0.0] / table_train.loc['All', 'All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0, 1.0] / table_test.loc['All', 'All']\n",
    "test_tII_errors = table_test.loc[1.0, 0.0] / table_test.loc['All', 'All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GridSearchCV to optimize model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning_rate shrinks the contribution of each tree\n",
    "Tune Learning Rate for Gradient Boosting with XGBoost in Python\n",
    "by Jason Brownlee on September 16, 2016 in XGBoost\n",
    "\n",
    "A problem with gradient boosted decision trees is that they are quick to learn and overfit training data.\n",
    "\n",
    "One effective way to slow down learning in the gradient boosting model is to use a learning rate, also called shrinkage (or eta in XGBoost documentation).\n",
    "\n",
    "* Gradient boosting involves creating and adding trees to the model sequentially.\n",
    "\n",
    "* New trees are created to correct the residual errors in the predictions from the existing sequence of trees.\n",
    "\n",
    "* The effect is that the model can quickly fit, then overfit the training dataset.\n",
    "\n",
    "A technique to slow down the learning in the gradient boosting model is to apply a weighting factor for the corrections by new trees when added to the model. This weighting is called the shrinkage factor or the learning rate, depending on the literature or the tool.\n",
    "\n",
    "Naive gradient boosting is the same as gradient boosting with shrinkage where the shrinkage factor is set to 1.0. **Setting values less than 1.0 has the effect of making less corrections for each tree added to the model. This in turn results in more trees that must be added to the model.**\n",
    "\n",
    "It is common to have small values in the range of 0.1 to 0.3, as well as values less than 0.1. A high learning rate can suggest that n_estimators (number of trees) is too low.\n",
    "\n",
    "### n_estimators represents the number of trees in the forest.\n",
    "Usually the higher the number of trees the better to learn the data. However, adding a lot of trees can slow down the training process considerably, therefore we do a parameter search to find the sweet spot.\n",
    "\n",
    "### max_depth indicates how deep the built tree can be.\n",
    "The deeper the tree, the more splits it has and it captures more information about how the data. Models tend to overfit the training data at high depth levels (likely in the range of 1-10).\n",
    "\n",
    "### min_samples_split represents the minimum number of samples required to split an internal node.\n",
    "This can vary between considering at least one sample at each node to considering all of the samples at each node. When we increase this parameter, the tree becomes more constrained as it has to consider more samples at each node (specify percentage of samples). When we require all of the samples at each node, the model cannot learn enough about the data (underfitting).\n",
    "\n",
    "### min_samples_leaf is the minimum number of samples required to be at a leaf node.\n",
    "This similar to min_samples_splits, however, this describe the minimum number of samples at the leafs. Increasing this value can cause underfitting.\n",
    "\n",
    "### max_features represents the number of features to consider when looking for the best split.\n",
    "Increasing max_features to consider all of the features often results in an overfitting.\n",
    "\n",
    "### subsample is used for fitting the individual base learners.\n",
    "If smaller than 1.0 this results in Stochastic Gradient Boosting. Subsample interacts with the parameter n_estimators. Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias.\n",
    "\n",
    "https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'loss': 'deviance', 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "params = {'loss': ['deviance'],\n",
    "          'n_estimators': [500 , 1000],\n",
    "          'learning_rate': [0.001, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "clf = GridSearchCV(gbc, params, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04127666104035599\n",
      "Percent Type II errors: 0.19610250115083627\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.04539877300613497\n",
      "Percent Type II errors: 0.19325153374233128\n"
     ]
    }
   ],
   "source": [
    "# Set parameters to optimized values\n",
    "params = {'loss': 'deviance',\n",
    "          'n_estimators': 500,\n",
    "          'learning_rate': 0.01\n",
    "}\n",
    "\n",
    "# Initialize and fit the model\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0, 1.0] / table_train.loc['All', 'All']\n",
    "train_tII_errors = table_train.loc[1.0, 0.0] / table_train.loc['All', 'All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0, 1.0] / table_test.loc['All', 'All']\n",
    "test_tII_errors = table_test.loc[1.0, 0.0] / table_test.loc['All', 'All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "params = {'loss': ['deviance'],\n",
    "          'n_estimators': [500],\n",
    "          'learning_rate': [0.01],\n",
    "          'max_depth': [2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "clf = GridSearchCV(gbc, params, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03851465398189351\n",
      "Percent Type II errors: 0.18505447291698635\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.04478527607361963\n",
      "Percent Type II errors: 0.18834355828220858\n"
     ]
    }
   ],
   "source": [
    "# Set parameters to optimized values\n",
    "params = {'loss': 'deviance',\n",
    "          'n_estimators': 500,\n",
    "          'max_depth': 4,\n",
    "          'learning_rate': 0.01\n",
    "}\n",
    "\n",
    "# Initialize and fit the model\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0, 1.0] / table_train.loc['All', 'All']\n",
    "train_tII_errors = table_train.loc[1.0, 0.0] / table_train.loc['All', 'All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0, 1.0] / table_test.loc['All', 'All']\n",
    "test_tII_errors = table_test.loc[1.0, 0.0] / table_test.loc['All', 'All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 500, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "params = {'loss': ['deviance'],\n",
    "          'n_estimators': [500],\n",
    "          'learning_rate': [0.01],\n",
    "          'max_depth': [4],\n",
    "          'subsample': [0.2, 0.5, 1]\n",
    "}\n",
    "\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "clf = GridSearchCV(gbc, params, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03145619149915605\n",
      "Percent Type II errors: 0.19840417369955501\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.03803680981595092\n",
      "Percent Type II errors: 0.20061349693251534\n"
     ]
    }
   ],
   "source": [
    "# Set parameters to optimized values\n",
    "params = {'loss': 'deviance',\n",
    "          'n_estimators': 500,\n",
    "          'max_depth': 4,\n",
    "          'learning_rate': 0.01,\n",
    "          'subsample': 0.5\n",
    "}\n",
    "\n",
    "# Initialize and fit the model\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0, 1.0] / table_train.loc['All', 'All']\n",
    "train_tII_errors = table_train.loc[1.0, 0.0] / table_train.loc['All', 'All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0, 1.0] / table_test.loc['All', 'All']\n",
    "test_tII_errors = table_test.loc[1.0, 0.0] / table_test.loc['All', 'All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'max_features': 15, 'n_estimators': 500, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "params = {'loss': ['deviance'],\n",
    "          'n_estimators': [500],\n",
    "          'learning_rate': [0.01],\n",
    "          'max_depth': [4],\n",
    "          'subsample': [0.5],\n",
    "          'max_features': [13, 14, 15]\n",
    "}\n",
    "\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "clf = GridSearchCV(gbc, params, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.040355992020868495\n",
      "Percent Type II errors: 0.18183213134878012\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.05337423312883435\n",
      "Percent Type II errors: 0.18220858895705522\n"
     ]
    }
   ],
   "source": [
    "# Set parameters to optimized values\n",
    "params = {'loss': 'deviance',\n",
    "          'n_estimators': 500,\n",
    "          'max_depth': 4,\n",
    "          'learning_rate': 0.01,\n",
    "          'subsample': 0.5,\n",
    "          'max_features': 15\n",
    "}\n",
    "\n",
    "# Initialize and fit the model\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0, 1.0] / table_train.loc['All', 'All']\n",
    "train_tII_errors = table_train.loc[1.0, 0.0] / table_train.loc['All', 'All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0, 1.0] / table_test.loc['All', 'All']\n",
    "test_tII_errors = table_test.loc[1.0, 0.0] / table_test.loc['All', 'All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineer new feature (interaction between age and happiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define outcome and predictors\n",
    "# Set our outcome to 0 and 1\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Make interaction variable\n",
    "df['age_int_hap'] = df['agea'] * df['happy']\n",
    "\n",
    "# Add interaction variable to X\n",
    "X = pd.concat([X, df['age_int_hap']], axis=1)\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>age_int_hap</th>\n",
       "      <th>CH</th>\n",
       "      <th>CZ</th>\n",
       "      <th>DE</th>\n",
       "      <th>ES</th>\n",
       "      <th>NO</th>\n",
       "      <th>SE</th>\n",
       "      <th>age_int_hap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>531.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8589</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8590</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8591</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8592</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8593</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8147 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  gndr  \\\n",
       "0        6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   2.0   \n",
       "1        6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   2.0   \n",
       "2        6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   1.0   \n",
       "3        6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   2.0   \n",
       "4        6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   2.0   \n",
       "...    ...    ...      ...      ...     ...    ...      ...     ...   ...   \n",
       "8589     7    3.0      4.0      5.0     3.0    6.0      6.0     2.0   1.0   \n",
       "8590     7    5.0      6.0      4.0     4.0   10.0      6.0     3.0   1.0   \n",
       "8591     7    4.0      5.0      7.0     6.0    8.0      6.0     3.0   1.0   \n",
       "8592     7    5.0      8.0      8.0     6.0    9.0      7.0     3.0   1.0   \n",
       "8593     7    2.0      6.0      7.0     5.0    7.0      7.0     4.0   2.0   \n",
       "\n",
       "      agea  age_int_hap  CH  CZ  DE  ES  NO  SE  age_int_hap  \n",
       "0     60.0        480.0   1   0   0   0   0   0        480.0  \n",
       "1     59.0        531.0   1   0   0   0   0   0        531.0  \n",
       "2     24.0        168.0   1   0   0   0   0   0        168.0  \n",
       "3     64.0        640.0   1   0   0   0   0   0        640.0  \n",
       "4     55.0        440.0   1   0   0   0   0   0        440.0  \n",
       "...    ...          ...  ..  ..  ..  ..  ..  ..          ...  \n",
       "8589  18.0        108.0   0   0   0   0   0   1        108.0  \n",
       "8590  15.0        150.0   0   0   0   0   0   1        150.0  \n",
       "8591  44.0        352.0   0   0   0   0   0   1        352.0  \n",
       "8592  15.0        135.0   0   0   0   0   0   1        135.0  \n",
       "8593  15.0        105.0   0   0   0   0   0   1        105.0  \n",
       "\n",
       "[8147 rows x 18 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04173699555009974\n",
      "Percent Type II errors: 0.18121835200245512\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.05644171779141104\n",
      "Percent Type II errors: 0.18466257668711655\n"
     ]
    }
   ],
   "source": [
    "# Set parameters to optimized values\n",
    "params = {'loss': 'deviance',\n",
    "          'n_estimators': 500,\n",
    "          'max_depth': 4,\n",
    "          'learning_rate': 0.01,\n",
    "          'subsample': 0.5,\n",
    "          'max_features': 15\n",
    "}\n",
    "\n",
    "# Initialize and fit the model\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0, 1.0] / table_train.loc['All', 'All']\n",
    "train_tII_errors = table_train.loc[1.0, 0.0] / table_train.loc['All', 'All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0, 1.0] / table_test.loc['All', 'All']\n",
    "test_tII_errors = table_test.loc[1.0, 0.0] / table_test.loc['All', 'All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "The adjustments I made using GridSearchCV to optimize parameters and feature engineering made very little difference in the training and test set accuracies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
